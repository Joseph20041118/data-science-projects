{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# House Price ML \u2014 Starter Notebook\n", "\n", "This notebook trains and compares two regression models on a housing dataset.\n", "- Preferred input: `data/house_prices.csv` (your custom dataset).\n", "- Fallback: use **sklearn California Housing** dataset (auto-load).\n", "\n", "**Pipeline**\n", "1. Load data (local CSV or sklearn fallback)\n", "2. Quick EDA (head/info/describe + missing values)\n", "3. Train/validation split\n", "4. Preprocessing (numeric impute + scaling)\n", "5. Models: Linear Regression, Random Forest\n", "6. Metrics: MAE, RMSE, R\u00b2 (on validation set)\n", "7. Save plots to `plots/` and model to `model.pkl`"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 0) Imports\n", "import os\n", "import joblib\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.impute import SimpleImputer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.ensemble import RandomForestRegressor"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 1) Load data\n", "# Try to load your own CSV first (place a file at data/house_prices.csv with a 'price' target column).\n", "# If not found, fall back to sklearn California Housing dataset.\n", "csv_path = 'data/house_prices.csv'\n", "\n", "if os.path.exists(csv_path):\n", "    df = pd.read_csv(csv_path)\n", "    print(f'Loaded local CSV: {csv_path}')\n", "else:\n", "    from sklearn.datasets import fetch_california_housing\n", "    cali = fetch_california_housing(as_frame=True)\n", "    df = cali.frame.copy()\n", "    # create a \"price\" column (target) and keep others as features\n", "    df = df.rename(columns={'MedHouseVal': 'price'})\n", "    print('Loaded sklearn California Housing dataset as fallback.')\n", "\n", "print('Shape:', df.shape)\n", "df.head()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 2) Quick EDA\n", "display(df.head())\n", "display(df.describe().T)\n", "\n", "print('\\nData types:')\n", "print(df.dtypes)\n", "\n", "# Missing values summary\n", "missing = df.isna().sum().sort_values(ascending=False)\n", "print('\\nMissing values per column:')\n", "print(missing[missing > 0] if missing.sum() > 0 else 'No missing values detected.')"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 3) Define target and features\n", "# Try to detect a reasonable target column. Default to 'price'.\n", "candidate_targets = ['price', 'SalePrice', 'target']\n", "target_col = None\n", "for c in candidate_targets:\n", "    if c in df.columns:\n", "        target_col = c\n", "        break\n", "\n", "if target_col is None:\n", "    # If none found, assume the last column is the target (not ideal, but makes notebook runnable).\n", "    target_col = df.columns[-1]\n", "    print(f'No standard target found; using last column as target: {target_col}')\n", "\n", "y = df[target_col]\n", "X = df.drop(columns=[target_col])\n", "\n", "# Keep only numeric features for this simple baseline\n", "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n", "X = X[num_cols]\n", "print('Using numeric features:', num_cols[:10], '...' if len(num_cols) > 10 else '')"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 4) Train/validation split\n", "X_train, X_valid, y_train, y_valid = train_test_split(\n", "    X, y, test_size=0.2, random_state=42\n", ")\n", "X_train.shape, X_valid.shape"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 5) Preprocessing pipeline for numeric columns\n", "numeric_transformer = Pipeline(steps=[\n", "    ('imputer', SimpleImputer(strategy='median')),\n", "    ('scaler', StandardScaler())\n", "])\n", "\n", "preprocess = ColumnTransformer(\n", "    transformers=[('num', numeric_transformer, X_train.columns)]\n", ")"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 6) Define models\n", "linreg = Pipeline(steps=[('preprocess', preprocess),\n", "                        ('model', LinearRegression())])\n", "\n", "rf = Pipeline(steps=[('preprocess', preprocess),\n", "                     ('model', RandomForestRegressor(\n", "                         n_estimators=300, random_state=42, n_jobs=-1\n", "                     ))])"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 7) Train\n", "linreg.fit(X_train, y_train)\n", "rf.fit(X_train, y_train)\n", "print('Training completed.')"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 8) Evaluate\n", "def eval_regression(model, Xv, yv, name='model'):\n", "    preds = model.predict(Xv)\n", "    mae = mean_absolute_error(yv, preds)\n", "    rmse = mean_squared_error(yv, preds, squared=False)\n", "    r2 = r2_score(yv, preds)\n", "    print(f'[{name}] MAE={mae:.4f}  RMSE={rmse:.4f}  R2={r2:.4f}')\n", "    return {'name': name, 'MAE': mae, 'RMSE': rmse, 'R2': r2}\n", "\n", "res_lin = eval_regression(linreg, X_valid, y_valid, 'LinearRegression')\n", "res_rf  = eval_regression(rf, X_valid, y_valid, 'RandomForest')\n", "\n", "results = pd.DataFrame([res_lin, res_rf])\n", "results"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 9) Plot: Predicted vs Actual (for the best model)\n", "best = res_rf if res_rf['RMSE'] < res_lin['RMSE'] else res_lin\n", "best_name = best['name']\n", "best_model = rf if best_name == 'RandomForest' else linreg\n", "\n", "preds = best_model.predict(X_valid)\n", "\n", "plt.figure(figsize=(6,6))\n", "plt.scatter(y_valid, preds, alpha=0.4)\n", "plt.xlabel('Actual')\n", "plt.ylabel('Predicted')\n", "plt.title(f'Predicted vs Actual \u2014 {best_name}')\n", "plot_path = 'plots/pred_vs_actual.png'\n", "plt.savefig(plot_path, bbox_inches='tight', dpi=150)\n", "plt.show()\n", "\n", "print(f'Plot saved to {plot_path}')"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 10) (Optional) Feature importance for RandomForest\n", "if best_name == 'RandomForest':\n", "    # Extract feature importances after preprocessing\n", "    rf_model = best_model.named_steps['model']\n", "    feature_names = best_model.named_steps['preprocess'].transformers_[0][2]\n", "    importances = pd.Series(rf_model.feature_importances_, index=feature_names).sort_values(ascending=False)\n", "    display(importances.head(15))\n", "\n", "    plt.figure(figsize=(8,5))\n", "    importances.head(15).plot(kind='bar')\n", "    plt.title('Top 15 Feature Importances (RandomForest)')\n", "    plt.tight_layout()\n", "    plot_path2 = 'plots/feature_importance.png'\n", "    plt.savefig(plot_path2, bbox_inches='tight', dpi=150)\n", "    plt.show()\n", "    print(f'Plot saved to {plot_path2}')\n", "else:\n", "    print('Feature importances shown only for RandomForest.')"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# 11) Save best model\n", "joblib.dump(best_model, 'model.pkl')\n", "print('Saved model to model.pkl')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}